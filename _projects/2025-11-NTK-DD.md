---
title: "Neural Tangent Kernel: on Double Descent"
collection: projects
category: school
permalink: /projects/2025-11-NTK-DD
# venue: "Department of Electrical Engineering"
date: 2025-11-12
# location: "National Taiwan University"
excerpt: "This presentation discusses the double descent behavior of neural network training by linking it with that of kernel regression via the Neural Tangent Kernel. Along the way, the replica trick is introduced to derive the analytic formula for the generalization error of kernel regression. *Course presentation for the course \"Physical Theories of (Machine) Learning\" given in the fall of 2025 by Prof. [Miranda Chih-Ning Cheng](https://sites.google.com/site/mcheng0606/).*"
---

> This is a course presentation for the course \"Physical Theories of (Machine) Learning\" given in the fall of 2025 by Prof. [Miranda Chih-Ning Cheng](https://sites.google.com/site/mcheng0606/)

# Abstract
Unlike the classical U-shaped bias-variance tradeoff, we see a second descent in the generalization error when we increase the size of the network in modern machine learning. This is coined the double descent behavior, which hints at us that "the larger the model, the better!" In this presentation, I link the double descent behavior of neural network training with that of ridgeless kernel regression via the Neural Tangent Kernel. Along the way, the replica trick is introduced to derive an analytic formula for the generalization of kernel regression.

# Slides
Download the slides for the talk [here](/files/slides/projects/2025_NTK_Double_Descent.pdf).
<embed src="/files/slides/projects/2025_NTK_Double_Descent.pdf" type="application/pdf" width="100%" height="600px" />

# Main References
- Adlam et al., "[The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization](https://arxiv.org/abs/2008.06786)."
- Canatar et al., "[Spectral bias and task-model alignment explain generalization in kernel regression and infinitely wide neural networks](https://www.nature.com/articles/s41467-021-23103-1)."
- R. Speicher, "[High Dimensional Analysis: Random Matrices and Machine Learning](https://rolandspeicher.com/lectures/course-on-high-dimensional-analysis-random-matrices-and-machine-learning-summer-term-2023/)," lecture notes, Saarland University.