---
title: 'Bregman Divergence is a Squared Distance'
date: 2025-08-23
permalink: /posts/2025/08/blog-post-3/
tags:
  - information geometry
  - information theory
  - geometry
excerpt: "This note demonstrates why the Bregman divergence can be seen as an asymmetric squared distance. This topic is deeply related to the field of information geometry."
---

In the last blog on mirror descent, we mentioned how we can treat Bregman divergences as squared distances, but without any further explanations! Therefore, this post is to elaborate on it. This is a basic result from information geometry, a subject under information theory that utilizes the tools from differential geometry. However, do not worry, as this post contains nothing from differential geometry nor information theory.

# Results
We shall state the results here, the proofs to the statements are some boring algebra and are deferred to the end.

## Bregman divergence is a squared distance
The first result is the "law of cosines" satisfied by the Bregman divergence: for points \\(x_1,x_2,x_3\in\mathfrak{X}\subseteq V\\) (the notations are as defined in the previous two posts),
<p>
$$\begin{equation}
	B_F(x_1, x_3) = B_F(x_1, x_2) + B_F(x_2, x_3) + \langle x_1 - x_2, \nabla F(x_2) - \nabla F(x_3) \rangle.
\end{equation}$$
</p>
And in the special case where the *orthogonality condition* \\(\langle x_1 - x_2, \nabla F(x_2) - \nabla F(x_3) \rangle\\) is met, we obtain the "Pythagoras theorem":
<p>
$$\begin{equation}
	B_F(x_1, x_3) = B_F(x_1, x_2) + B_F(x_2, x_3).
\end{equation}$$
</p>
If we view \\(B_F(x_1,x_2)\\) as some form of an asymmetric squared distance over the "edge" connecting \\(x_1\\) from \\(x_2\\), then the equations above are direct analogs of the usual law of cosines and Pythagoras theorem we are so accustomed to from high school[^1]. The other term \\(\langle x_1 - x_2, \nabla F(x_2) - \nabla F(x_3) \rangle\\) is then an asymmetric inner product between the edge connecting \\(x_1\\) from \\(x_2\\) and the edge connecting \\(x_2\\) from \\(x_3\\).

[^1]: I'm assuming the Taiwanese education system here.

Let's make sense of their validity in the usual Euclidean distance case: Let \\(F(x) = || x ||_2^2\\), then \\(\nabla F(x) = 2x\\) and \\(B_F(x_1, x_2) = ||x_1-x_2||_2^2\\), then equation (1) becomes:
<p>
$$
\left\|x_1 - x_3\right\|_2^2 = \left\|x_1 - x_2\right\|_2^2 + \left\|x_2 - x_3\right\|_2^2 - 2 \left\|x_1 - x_2\right\|_2 \left\|x_2 - x_3\right\|_2 \cos\theta.
$$
</p>
This is the Euclidean law of cosine, where \\(\theta\\) is the angle between the vectors \\(x_1-x_2\\) and \\(x_3-x_2\\).

## Primal and dual geodesics
Back to the more general case, let me persuade to you how equation (1) is indeed the law of cosine, just with a more exotic notion of edges.

Since we are working under the framework of information geometry, let us assume that \\(\mathfrak{X} = \nabla([n])\\) is a probability simplex over a support of size \\(n\\), and all the points on it is a valid probability distribution.


# Some more properties of the Bregman divergence
Last time we have shown how, given a differentiable strictly convex closed function \\(F\\), we are able to map between the primal and dual (mirror) spaces. The notion of primal and dual is everywhere, appearing in anything that relates with the Bregman divergence, and of course, in information geometry.


# Proofs to statements