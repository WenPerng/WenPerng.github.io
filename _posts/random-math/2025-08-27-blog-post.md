---
title: 'Matrix Inversion Lemmas'
date: 2025-08-27
permalink: /posts/random-math/matrix-inversion-lemma
tags:
  - linear algebra
categories:
  - Random Math
excerpt: ''
---

> This post introduces two useful matrix inversion lemmas, the Woodbury formula that inverts matrix of the form \\(A+UCV\\), and the inverse of a \\(2\times2\\) block-partitioned matrix. So useful that I have actually utilized them in my research at EPFL.

Though they may seem daunting at first sight, they are actually quite trivial results with simple proofs. Without further adieu, let's get on with them. 

# Woodbury's formula
The [Woodbury matrix inversion formula](https://en.wikipedia.org/wiki/Woodbury_matrix_identity#Direct_proof) is of the form
<p>

$$\boxed{
(A+UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1} + VA^{-1}U)^{-1} V A^{-1}}.
$$
</p>
This lemma is especially useful is the size of \\(A\\) is large, but the size of \\(C\\) is small.

## Proof
The proof is as below: for matrices \\(X\\), \\(Y\\) such that the following operations are valid.
<p>
$$
\begin{align*}
    \left(\mathbb{I} - XY\right)^{-1} &= \sum_{k=0}^{\infty} (XY)^k \\
    &= \mathbb{I} + X \left(\sum_{k=0}^{\infty} (YX)^n \right) Y \\
    &= \mathbb{I} + X \left(YX\right)^{-1} Y
\end{align*}
$$
</p>
By setting \\(X = A^{-1} U\\) and \\(Y = CV\\), we have
<p>
$$
\begin{align*}
    \left(A + UCV\right)^{-1} &= \left(\mathbb{I} + A^{-1}UCV\right) A^{-1}\\
    &= \left(\mathbb{I} + XY\right) A^{-1} \\
    &= \left(\mathbb{I} + X \left(\mathbb{I} + YX\right)^{-1} Y\right) A^{-1} \\
    &= A^{-1} + A^{-1} U \left(\mathbb{I} + CVA^{-1} U\right) CV A^{-1} \\
    &= A^{-1} - A^{-1}U(C^{-1} + VA^{-1}U)^{-1} V A^{-1}. \;\;\;\;\; \blacksquare
\end{align*}
$$
</p>
Thus it is proven.


# Inverse of block-partitioned matrix
For block-partitioned matrices, especially the \\(2\times2\\) case, we have a nice formula for inverting it. Assume \\(A\\) is invertible, then
<p>
$$ \boxed{
\left[\begin{array}{c:c}
A & B \\ \hdashline
C & D
\end{array}\right]^{-1} = \left[\begin{array}{c:c}
A^{-1} + A^{-1}B\Delta^{-1}CA^{-1} & -A^{-1}B\Delta^{-1} \\ \hdashline
-\Delta^{-1}CA^{-1} & \Delta^{-1}
\end{array}\right]},
$$
</p>
where
<p>
$$
\Delta = D - CA^{-1}B.
$$
</p>

This term \\(\Delta\\) is also known as the *Schur complement* of \\(A\\) of the whole matrix.

## Proof
The proof is trivial once you know the trick. Remember how we obtain the inverse to a matrix by consecutively applying row operations on an augmented matrix, we will now extend the procedure to block-partitioned matrices. The subtlety lies in the fact that matrix multiplication is NOT commutative, hence, one should be careful whether a matrix is multiplied for the left or the right. For row operations, the matrices are multiplied from the left:
<p>
$$
\left[\begin{matrix}
    1 & 2 \\ 0 & 1
\end{matrix}\right] \left[\begin{matrix}
    a & b \\ c & d
\end{matrix}\right] = \left[\begin{matrix}
    a + 2c & b + 2d \\ c & d
\end{matrix}\right].
$$
</p>
Henceforth, we have the following derivation:
<p>
$$
\begin{aligned}
    \left[\begin{array}{cc:cc}
        A & B & \mathbb{I} & 0 \\
        C & D & 0 & \mathbb{I}
    \end{array}\right] &\rightarrow \left[\begin{array}{cc:cc}
        A & B & \mathbb{I} & 0 \\
        C - {\color{teal}CA^{-1}}A & D - {\color{teal}CA^{-1}}B & -{\color{teal}CA^{-1}} & \mathbb{I}
    \end{array}\right] \\
    &\rightarrow \left[\begin{array}{cc:cc}
        A & B - {\color{teal}B\Delta^{-1}}\Delta & \mathbb{I} + {\color{teal}B\Delta^{-1}}CA^{-1} & - {\color{teal}B\Delta^{-1}} \\
        0 & \Delta & -CA^{-1} & \mathbb{I}
    \end{array}\right] \\
    &\rightarrow \left[\begin{array}{cc:cc}
        \mathbb{I} & 0 & {\color{teal}A^{-1}} + {\color{teal}A^{-1}}B\Delta^{-1}CA^{-1} & - {\color{teal}A^{-1}}B\Delta^{-1} \\
        0 & \mathbb{I} & -{\color{teal}\Delta^{-1}}CA^{-1} & {\color{teal}\Delta^{-1}}
    \end{array}\right].\;\;\;\;\;\blacksquare
\end{aligned}
$$
</p>
The block on the right is the derived inverse.