---
title: 'Complex Gradient Descent and Lagrange Multipliers'
date: 2025-09-03
permalink: /posts/2025/09/blog-post-03/
tags:
  - linear algebra
  - optimization
excerpt: ""
---

> This post applies the complex vector differentiation developed in the last post to discuss gradient descent algorithm for unconstrained optimization. I also discuss the corresponding Lagrange multiplier formalism for constrained optimization.

Since we are dealing with optimization algorithms, let us consider the function to be optimize as \\(g(\boldsymbol{u})\in\mathbb{R} = f(\boldsymbol{v})\\) with \\(\boldsymbol{u}\in\mathbb{C}^{2n}\\) and \\(\boldsymbol{v}\in\mathbb{R}^{2n}\\). The notations used in this post continues from the last post.

# Gradient descent
Our goal is to establish a descent algorithm of the form
<p>
$$
    \boldsymbol{z}_{t+1} = \boldsymbol{z}_{t} - \mu \boldsymbol{d}_{t}.
$$
</p>
Given an inner product \\(\langle \cdot , \cdot \rangle\\) which we will specify later in examples, we can set the vector \\(\boldsymbol{d}_{t}\\) as satisfying
<p>
$$
    \frac{\partial g(\boldsymbol{u}_{t})}{\partial \boldsymbol{u}} [\mathrm{d} \boldsymbol{u}] = 2 \mathrm{Re}\left\{\frac{\partial g(\boldsymbol{u}_{t})}{\partial \boldsymbol{z}} [\mathrm{d} \boldsymbol{z}]\right\} = \langle \boldsymbol{d}_{t}, \mathrm{d} \boldsymbol{z}\rangle
$$
</p>
for all \\(\mathrm{d} \boldsymbol{u} = [\mathrm{d} \boldsymbol{z}; \mathrm{d} \boldsymbol{z}^\*] \in \mathbb{C}^{2n}\\). The vector \\(\boldsymbol{d}_{t}\\) obtained is the gradient associated with \\(\langle\cdot,\cdot\rangle\\).

The gradient vector can be extended to be \\(\overline{\boldsymbol{d}} _{t} = [\boldsymbol{d} _{t}; \boldsymbol{d} _t^\*]\\) acting on \\(\boldsymbol{u} _{t}\\).

## Performance analysis
For our discussion on the performance guarantees on the descent algorithm, it is required that we make some local assumptions on the optimizing function \\(g\\).

### Assumptions on function
Let the norm associated with the given inner product \\(\langle\cdot,\cdot\rangle\\) be \\(\|\cdot\|\\). Note that it might no longer be the usual complex Euclidean norm.

The gradients are \\(\delta\\)-Lipschitz, i.e., let the gradient at \\(\boldsymbol{u}\\) be noted by \\(\boldsymbol{d}(\boldsymbol{u})\\), then
<p>
$$\boxed{
    \left\| \boldsymbol{d}(\boldsymbol{u}_1) - \boldsymbol{d}(\boldsymbol{u}_2) \right\| \le \delta \left\| \boldsymbol{u}_1 - \boldsymbol{u}_2 \right\|
}.
$$
</p>

Secondly, the function is assumed to be \\(\nu\\)-strongly convex, i.e., for all \\(\boldsymbol{u}\\) and \\(\boldsymbol{u}_0\\),
<p>

$$\boxed{
    g(\boldsymbol{u}) \ge g(\boldsymbol{u}_0) + \frac{\partial g(\boldsymbol{u}_0)}{\partial \boldsymbol{u}}[\boldsymbol{u} - \boldsymbol{u}_0] + \frac{\nu}{2} \|\boldsymbol{u} - \boldsymbol{u}_0 \|^2
}.
$$
</p>

### Convergence
Firstly, note that
<p>
$$
\langle \boldsymbol{d}_{t}^*, \mathrm{d} \boldsymbol{z}^* \rangle= \langle \boldsymbol{d}_{t}, \mathrm{d} \boldsymbol{z} \rangle^* \Rightarrow \frac{\partial g(\boldsymbol{u}_{t})}{\partial \boldsymbol{u}}[\mathrm{d}\boldsymbol{u}] = \langle \overline{\boldsymbol{d}}_{t}, \mathrm{d}\boldsymbol{u}\rangle.
$$
</p>

Consider the unique minimizer to \\(g\\) as \\(\boldsymbol{u} _{\star} = [\boldsymbol{z} _{\star};\boldsymbol{z}^\* _{\star}]\\), then define the deviation from the minimizer as \\(\widetilde{\boldsymbol{u}} _{t} = \boldsymbol{u} _{\star} - \boldsymbol{u} _{t}\\). Let \\(\boldsymbol{d} _\star = 0\\) be the gradient at the minimizer, then the norm of the error is
<p>

$$
\begin{align*}
    \widetilde{\boldsymbol{u}}_{t+1} &= \widetilde{\boldsymbol{u}}_{t} + \mu \overline{\boldsymbol{d}}_{t} \\
    \Rightarrow \|\widetilde{\boldsymbol{u}}_{t+1}\|^2 &= \|\widetilde{\boldsymbol{u}}_{t}\|^2 + 2 \mu \langle \widetilde{\boldsymbol{u}}_{t}, \overline{\boldsymbol{d}}_{t}\rangle + \mu^2 \| \overline{\boldsymbol{d}_{t}} \|^2 \\
    &= \|\widetilde{\boldsymbol{u}}_{t}\|^2 + 2 \mu \frac{\partial g(\boldsymbol{u}_{t})}{\partial \boldsymbol{u}}[\widetilde{\boldsymbol{u}}_{t}] + \mu^2 \| \overline{\boldsymbol{d}}_{t} - \overline{\boldsymbol{d}}_{\star}\|^2 \\
    &\le \|\widetilde{\boldsymbol{u}}_{t}\|^2 + 2\mu \left(g(\boldsymbol{u}_{t}) - g(\boldsymbol{u}_{\star}) - \frac{\nu}{2}\|\widetilde{\boldsymbol{u}}_{t}\|^2\right) + \mu^2 \delta^2 \| \widetilde{\boldsymbol{u}}_{t}\|^2 \\
    &= (1 - \mu \nu + \mu^2\delta^2) \| \widetilde{\boldsymbol{u}}_{t}\|^2 + 2\mu \left(g(\boldsymbol{u}_t) - g(\boldsymbol{u}_{\star})\right) \\
    &\le (1 - \mu \nu + \mu^2\delta^2) \| \widetilde{\boldsymbol{u}}_{t}\|^2 + 2\mu \left( - \frac{\nu}{2} \|\widetilde{\boldsymbol{u}_{t}}\|^2\right) \\
    &\le (1 - 2 \mu \nu + \mu^2\delta^2) \| \widetilde{\boldsymbol{u}}_{t}\|^2.
\end{align*}
$$
</p>

If we choose a step-size \\(\mu\\) such that
<p>
$$\boxed{
    1 - 2 \mu \nu + \mu^2\delta^2 \in [0,1)
},$$
</p>
we hence obtain the convergence of the gradient descent algorithm.

Note that since \\(\delta \ge \nu > 0\\), we can obtain the simpler criterion of \\(\mu \in (0,2\nu/\delta^2)\\).

## Example
I will show that the two inner products introduced in the last post ensures convergence of the gradient descent algorithm.

### Hermitian inner product over \\(\mathbb{C}^{2n}\\)
The inner product used is
<p>
$$\langle \boldsymbol{u}_1, \boldsymbol{u}_2\rangle = \boldsymbol{u}_1^{\mathsf{H}} \boldsymbol{u}_2,$$
</p>
the associated norm is simply the usual norm of a complex vector. Henceforth, the two assumptions on Lipschitz gradient and strong-convexity are reasonable. The gradient descent is then
<p>
$$
\boldsymbol{u}_{t+1} = \boldsymbol{u}_{t} - \mu \left(\frac{\partial g(\boldsymbol{u}_{t})}{\partial \boldsymbol{u}}\right)^{\mathsf{H}}.
$$
</p>

### Real inner product over \\(\mathbb{C}^{n}\\)
The inner product used is
<p>
$$\langle \boldsymbol{z}_1, \boldsymbol{z}_2\rangle = 2 \mathrm{Re}\\\{\boldsymbol{z}_1^{\mathsf{H}} \boldsymbol{z}_2\\\},$$
</p>
restricted on \\(\mathbb{C}^{n}\\) instead of \\(\mathbb{C}^{2n}\\) as in the previous example.

Note that since for \\(\boldsymbol{u} _1 = [\boldsymbol{z} _1; \boldsymbol{z} _1^\*]\\) and \\(\boldsymbol{u} _2 = [\boldsymbol{z} _2; \boldsymbol{z} _2^\*]\\),
<p>
$$
    \boldsymbol{u}_1^{\mathsf{H}} \boldsymbol{u}_2 = \boldsymbol{z}_1^{\mathsf{H}} \boldsymbol{z}_2 + \boldsymbol{z}_1^{\mathsf{T}} \boldsymbol{z}_2^* = 2 \mathrm{Re}\{\boldsymbol{z}_1^{\mathsf{H}} \boldsymbol{z}_2\}.
$$
</p>
Henceforth, we see that the real inner product over \\(\boldsymbol{z}\in\mathbb{C}^{n}\\) is equivalent in operation to the Hermitian inner product over \\(\boldsymbol{u} \in \mathbb{C}^{2n}\\). The gradient descent is then
<p>
$$
\boldsymbol{z}_{t+1} = \boldsymbol{z}_{t} - \mu \left(\frac{\partial g(\boldsymbol{u}_{t})}{\partial \boldsymbol{z}}\right)^{\mathsf{H}}.
$$
</p>

# Lagrange multipliers
As we have seen above, by using the real inner product over \\(\boldsymbol{z}\\), we can restrict our discussions to half the dimension as that of \\(\boldsymbol{u}\\). This is quite favorable, and I shall work in this fashion from now on if possible.

The method of Lagrange multiplier is used to find extrema over differentiable constrained sets. Consider optimizing a real function \\(g(\boldsymbol{u})\\) over the constrained set \\(\boldsymbol{h}(\boldsymbol{u}) = \boldsymbol{0}\\). Note that \\(\boldsymbol{h}\\) is a vector constraint.

This problem can be solved by considering the Lagrangian
<p>
$$
\boxed{
    \mathcal{L} = g(\boldsymbol{u}) + \mathrm{Re} \left\{\boldsymbol{\lambda}^{\mathsf{H}} \boldsymbol{h}(\boldsymbol{u})\right\}
}
$$
</p>
with Lagrange multiplier vector \\(\boldsymbol{\lambda}\\), the optima should satisfy both \\(\boldsymbol{h}(\boldsymbol{u}) = \boldsymbol{0}\\) and
<p>

$$
\boxed{
    \frac{\partial \mathcal{L}}{\partial \boldsymbol{z}} = \boldsymbol{0}
}.
$$
</p>

Note how the differentiation is with respect to \\(\boldsymbol{z}\\) only!

## Proving the method
I'll obtain the complex form above from the method of Lagrange multipliers for real functions. Let us separate the real and imaginary parts of the terms: \\(\boldsymbol{\lambda} = \boldsymbol{\lambda} _1 + \mathrm{i} \boldsymbol{\lambda} _2\\) and \\(\boldsymbol{h}(\boldsymbol{u}) = \boldsymbol{h} _1(\boldsymbol{u}) + \mathrm{i} \boldsymbol{h} _2(\boldsymbol{u}) = \boldsymbol{k} _1(\boldsymbol{v}) + \mathrm{i} \boldsymbol{k} _2(\boldsymbol{v})\\). Then the Lagrangian construction given above is equivalent to its real counterpart:
<p>

$$
\begin{align*}
    \mathcal{L} &= g(\boldsymbol{u}) + \boldsymbol{\lambda}_1^{\mathsf{T}} \boldsymbol{h}_1(\boldsymbol{u}) + \boldsymbol{\lambda}_2^{\mathsf{T}} \boldsymbol{h}_2(\boldsymbol{u}) \\
    &= f(\boldsymbol{v}) + \boldsymbol{\lambda}_1^{\mathsf{T}} \boldsymbol{k}_1(\boldsymbol{v}) + \boldsymbol{\lambda}_2^{\mathsf{T}} \boldsymbol{k}_2(\boldsymbol{v}).
\end{align*}
$$
</p>

The optimality condition requires that
<p>

$$
\begin{align*}
    &\frac{\partial\mathcal{L}}{\partial \boldsymbol{v}} = \boldsymbol{0} = \left[\begin{matrix}
        \frac{\partial\mathcal{L}}{\partial \boldsymbol{x}} & \frac{\partial\mathcal{L}}{\partial \boldsymbol{y}}
    \end{matrix}\right] \\
    &\Rightarrow \frac{\partial\mathcal{L}}{\partial \boldsymbol{x}} = \frac{\partial\mathcal{L}}{\partial \boldsymbol{y}} = \boldsymbol{0} \\
    &\Rightarrow \frac{\partial\mathcal{L}}{\partial \boldsymbol{z}} = \frac{1}{2} \left(\frac{\partial\mathcal{L}}{\partial \boldsymbol{x}} - \mathrm{i} \frac{\partial\mathcal{L}}{\partial \boldsymbol{y}}\right) = \boldsymbol{0}. \;\;\;\;\;\blacksquare
\end{align*}
$$
</p>
Thus the validity of the formulation in the box above is verified.