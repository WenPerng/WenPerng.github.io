---
title: 'First Blog! On Mirror Descent'
date: 2025-08-21
permalink: /posts/2025/08/blog-post-21/
tags:
  - optimization
---

This is a simple blog post on mirror descent.

I learned this from a friend of mine, Zoya, who I met during my stay at ASL, EPFL in the summer of 2025.

# Descent methods revisited
A usual descent method is described by a recursion of the form
<p>
$$x_{t} = x_{t-1} - \eta g_{t},$$
</p>
where \\(\eta\\) is the step-size, and \\(g_{t}\\) is the descent direction. If the descent direction \\(g_{t}\\) is the gradient at \\(x_{t-1}\\), then the recursion is the gradient descent algorithm; if the direction is a subgradient, then the recursion is a subgradient descent; if the direction is the gradient multiplied by the inverse Hessian, then the recursion is the Newton's method.

Now, we can rewrite the recursion as an optimization problem of the form
<p>
$$ x_{t} = \arg\min_{x\in\mathbb{R}^n} \langle g_{t},x\rangle + \frac{1}{2\eta} \left\| x - x_{t-1} \right\|_2^2. $$
</p>
This can be readily checked via a simple differentiation.

What happens if we change the quadratic norm term at the back, also known as the *proximity term* with other forms of squared distances? This is the promise of mirror descent.

# What is mirror descent?
Let us consider a class of squared distances that can replace the  Euclidean squared distance we have above. These are called the Breman divergences.

## Bregman Divergence
Consider a strictly convex function \\(f:X\rightarrow\mathbb{R}\\), then the Bregman divergence associated with \\(f\\) for points \\(x\\) and \\(x' \in X\\) is defined to be
<p>
$$ B_f(x \| x') = f(x) - f(x') - \langle \nabla f(x') , x-x'\rangle.$$
</p>

The Bregman divergence acts like a squared distance although being asymmetric. The discussion of what that previous sentence mean is deferred to a future discussion on some basics of information geometry. So for the mean time, just bare with me here.

## Mirror descent
Now, replacing the proximity term in the first recursion with the Bregman divergence, we obtain
<p>
\begin{align*}
    x_{t} = \arg\min_{x\in\mathbb{R}^n} \langle g_t,x\rangle + \frac{1}{2\eta} B_f(x\|x_{t-1}).
\end{align*}
</p>

The choice of \\(f\\) is important as it changes the dynamic of the algorithm.

# Example of a mirror descent
## Euclidean distance

## KL divergence


# Why "Mirror"?