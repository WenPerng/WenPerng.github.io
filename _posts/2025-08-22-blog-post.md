---
title: 'On Mirror Descent (II): why "Mirror"?'
date: 2025-08-22
permalink: /posts/2025/08/blog-post-2/
tags:
  - optimization
  - convex optimization
excerpt: 'This is a simple blog post on explaining why mirror descent is called "mirror" descent. In short, the mirror descent can be seen as a descent method in the *mirror space*!'
---

The reason we call the mirror descent the "mirror" descent is because it can be viewed as a usual descent method in the *mirror space*.

# The gradient is NOT a vector
Consider \\(g_t\\) as the gradient of our target loss function (to be minimized) evaluated at the point \\(x_{t-1}\\). In the usual gradient descent over \\(\mathbb{R}^n\\), we write the next iterate point as \\(x_t = x_{t-1} - \eta g_t\\). However, as we have seen in [manifold optimization](/talks/2024-10-01-talk), more often then not, \\(x_{t-1}\\) and \\(g_t\\) does not live in the same space where their addition makes sense! But for now, we will only consider mirror descent over a subset \\(\mathfrak{X}\\) of a vector space \\(V\\) to make matters simple.

Recall that for a given function \\(\ell : \mathfrak{X} \rightarrow \mathbb{R}\\) defined on a convex set \\(\mathfrak{X} \subseteq V\\), we define its gradient at a point \\(x\in \mathfrak{X}\\) to be a *linear functional* \\(\langle g , \cdot \rangle\\) that satisfies
\\[
    \frac{\mathrm{d} \ell}{\mathrm{d} x} [h] = \langle g , h \rangle
\\]
for all tangent vectors \\(h \in T_x V\\). The tangent space \\(T_x V\\) of a vector space is identical to itself, hence we have \\(T_x V = V\\). All linear functionals defined on a vector space \\(V\\) constitue its *dual space* \\(V^\*\\) (sometimes[^1] also denoted as \\(V^\vee\\)). In the case of the dual space to a tangent space, we often denote it as \\(T^\*_xV\\), \\( (T_xV)^\* \\), or \\( (T_xV)^\vee \\), and call it the *cotangent space* of \\(V\\). Note that since \\(T_x V = V\\), we have \\(T_x^\* V = V^\*\\).

[^1]: Tu, Loring W., "An introduction to manifolds." (2007).

|            | Vector Space  | Dual Space              |
| :--------- | :-----------: | :---------------------: |
| Notation   | \\(V\\)       | \\(V^\*\\)              |
| Vector     | vectors       | dual vectors, covectors |
| Components | contravariant | covariant               |

Further note that although for finite dimensional \\(V\\), the two vector pacesThe table above shows that the usual *vectors* are those that reside in the vector space, while we call those that reside in the dual space the *covectors*. A gradient is a covector, it lives in a different space as the point \\(x\\), hence it cannot be added onto the point.

The mirror descent, then, is to apply descent methods in the dual space, also known as the mirror space in this context.

# Mirror map
consider a differentiable strictly convex closed function \\(F : \mathfrak{X} \rightarrow \mathbb{R}\\) defined over the same domain as the loss function \\(\ell\\), we will use it to create a *mirror map* that maps a point in the primal space, a subset of the original vector space \\(V\\), to the mirror space, a subset of the dual space \\(V^\*\\).

For a function to be strictly convex, it means that for any \\(x, x'\in \mathfrak{X}\\) and \\(\lambda\in[0,1]\\), we have \\(F(\lambda x + (1-\lambda)x') < \lambda F(x) + (1-\lambda) F(x')\\). For a function to be [closed](https://en.wikipedia.org/wiki/Closed_convex_function), its sublevel set is closed.

## Convex conjugate
The *convex conjugate* (also known as the *Fenchel conjugate* or the *Fenchel dual*) of a convex function \\(F\\) is denoted as \\(F^\*\\) and defined as
<p>
$$\boxed{
    F^*(y) = \sup_{x\in V} \left\{\langle y,x\rangle - F(x)\right\}
}.$$
</p>
This map basically finds the "largest gap" between the linear approximation of \\(F\\)  at \\(x\\). The inspiration behind such a definition is a lengthy one, and one should refer other works to understand them.

As \\(F\\) is strictly convex and closed, the convex conjugation acts as an [involution](https://en.wikipedia.org/wiki/Involution_(mathematics)) on it, i.e., \\((F^\*)^\* = F\\).

## Mirror map
Furthermore, as \\(F\\) is differentiable, we can actually compute the optima above as satisfying the relationship
<p>
$$\boxed{
    y = \nabla F(x)
}.$$
</p>
Interestingly enough, we also have its inverse function as
<p>
$$\boxed{
    x = \nabla F^*(y)
}.$$
</p>

Now we can see that \\(\nabla F\\) is a map from the primal space to the mirror space, THIS is the mirror map. We can now use this notion to continue on with our explaining of the mirror descent algorithm.

<br/><img src='/images/posts/2025-08-22-mirror-map.png'>

# Mirror descent
Recall the definition to the mirror descent:
<p>
$$\begin{aligned}
    x_{t}
    &= \arg\min_{x\in \mathfrak{X}} \langle g_t, x\rangle + \frac{1}{\eta} B_f(x, x_{t-1}) \\
    \Rightarrow 0 &= \eta g_{t} + \left.\nabla_{x} \left[ F(x) - F(x_{t-1}) - \left\langle \nabla F(x_{t-1}), x - x_{t-1}\right\rangle \right] \right|_{x=x_{t}} \\
	&= \eta g_{t} + \nabla F(x_{t}) - \nabla F(x_{t-1}) \\
	\Rightarrow \nabla F(x_{t}) &= \nabla F(x_{t-1}) - \eta g_{t} \\
	\Rightarrow x_{t} &= \nabla F^* \left(\nabla F(x_{t-1}) - \eta g_{t}\right).
\end{aligned}$$
</p>
We can see that in the mirror space, \\(\nabla F(x_{t-1})\\) performs a usual descent method to obtain \\(\nabla F(x_{t})\\). We finally obtain \\(x_{t}\\) by applying the inverse of the mirror map, viz., \\(\nabla F^\* = (\nabla F)^{-1}\\).

Hence the name "mirror descent". Voil√†.